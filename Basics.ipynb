{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spam Filter Program - Naive Bayes Classifier\n",
    "We want to build a program that classifies messages as Spam or Non-Spam. To do this we will use a naive bayes classification algorithm. The dataset we will use to train the algorithm was put together by Jose Hidalgo and is hosted at the UCI Machine Learning Repository. It contains 5,572 SMS messages that have already been classified by humans.\n",
    "\n",
    "## Exploring the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import pandas library\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import the dataset into a dataframe\n",
    "spam_data = pd.read_csv('SMSSpamCollection', sep='\\t', header=None,\n",
    "                       names = ['Label','SMS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 2 columns):\n",
      "Label    5572 non-null object\n",
      "SMS      5572 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 87.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# explore the set\n",
    "spam_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ham     4825\n",
      "spam     747\n",
      "Name: Label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# see how many messages are classified as spam vs not\n",
    "spamcounts = spam_data['Label'].value_counts()\n",
    "print(spamcounts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The set is 13.41% spam\n"
     ]
    }
   ],
   "source": [
    "# report percent of spam messages\n",
    "spam_percent = float(100*spamcounts[['spam']]/spam_data['Label'].count())\n",
    "print('The set is {:.2f}% spam'.format(spam_percent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determining training and testing sets\n",
    "We will use an 80:20 train:test split for our classifier. We will start by randomizing the dataset. For the purposes of this project we will use a random_state of 1 so that you can reproduce our results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# randomize the dataset\n",
    "random_spam_data = spam_data.sample(frac=1, random_state=1)\n",
    "\n",
    "# split the data into a training and test set\n",
    "train = random_spam_data.head(4458).reset_index()\n",
    "test = random_spam_data.tail(1114).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training set is 13.46% spam\n"
     ]
    }
   ],
   "source": [
    "# report percentage of spam data in the training set\n",
    "train_vals = train['Label'].value_counts()\n",
    "train_spam_per = float(100*train_vals[['spam']]/train_vals.sum())\n",
    "print('The training set is {:.2f}% spam'.format(train_spam_per))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test set is 13.20% spam\n"
     ]
    }
   ],
   "source": [
    "# report percentage of spam data in the test set\n",
    "test_vals = test['Label'].value_counts()\n",
    "test_spam_per = float(100*test_vals[['spam']]/test_vals.sum())\n",
    "print('The test set is {:.2f}% spam'.format(test_spam_per))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The proportion of spam in each of our samples closely match the spam proportion in the larger set, so we can consider each sample representative of the full dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the data\n",
    "To implement our algorithm we will need to convert the data into a format that is easier to parse. We are going to convert the \"SMS\" column to a series of columns, each representing one of the words in the overall vocavulary of the set. For each word (column) and message (row), the data point will indicate the number of times that the word appears in the message.\n",
    "To perform this operation we will also need to standardize the messages by removing punctuation and converting to lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1078</td>\n",
       "      <td>ham</td>\n",
       "      <td>Yep, by the pretty sculpture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4028</td>\n",
       "      <td>ham</td>\n",
       "      <td>Yes, princess. Are you going to make me moan?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>958</td>\n",
       "      <td>ham</td>\n",
       "      <td>Welp apparently he retired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4642</td>\n",
       "      <td>ham</td>\n",
       "      <td>Havent.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4674</td>\n",
       "      <td>ham</td>\n",
       "      <td>I forgot 2 ask ü all smth.. There's a card on ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index Label                                                SMS\n",
       "0   1078   ham                       Yep, by the pretty sculpture\n",
       "1   4028   ham      Yes, princess. Are you going to make me moan?\n",
       "2    958   ham                         Welp apparently he retired\n",
       "3   4642   ham                                            Havent.\n",
       "4   4674   ham  I forgot 2 ask ü all smth.. There's a card on ..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check head of original set\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1078</td>\n",
       "      <td>ham</td>\n",
       "      <td>yep  by the pretty sculpture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4028</td>\n",
       "      <td>ham</td>\n",
       "      <td>yes  princess  are you going to make me moan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>958</td>\n",
       "      <td>ham</td>\n",
       "      <td>welp apparently he retired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4642</td>\n",
       "      <td>ham</td>\n",
       "      <td>havent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4674</td>\n",
       "      <td>ham</td>\n",
       "      <td>i forgot 2 ask ü all smth   there s a card on ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index Label                                                SMS\n",
       "0   1078   ham                       yep  by the pretty sculpture\n",
       "1   4028   ham      yes  princess  are you going to make me moan \n",
       "2    958   ham                         welp apparently he retired\n",
       "3   4642   ham                                            havent \n",
       "4   4674   ham  i forgot 2 ask ü all smth   there s a card on ..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove all punctuation and convert to lowercase\n",
    "train['SMS'] = train['SMS'].str.replace(r'\\W',' ').str.lower()\n",
    "# check new output\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that our operation worked. Now, we need to generate a vocabulary list which will store all the unique words encountered in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# initialize list for training set vocabulary\n",
    "vocabulary = []\n",
    "\n",
    "# transform training set SMS column into list of strings\n",
    "train['SMS'] = train['SMS'].str.split()\n",
    "\n",
    "# iterate through each message and store words if they have not already been stored\n",
    "for sms in train['SMS']:\n",
    "    for word in sms:\n",
    "        if word not in vocabulary:\n",
    "            vocabulary.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# initialize dictionary that stores the word counts of each sms. Each entry will\n",
    "# start with a value of zero\n",
    "word_counts_per_sms = {unique_word: [0] * len(train['SMS']) for unique_word in vocabulary}\n",
    "\n",
    "# iterate through the sms messages and their corresponding indices\n",
    "for index, sms in enumerate(train['SMS']):\n",
    "    # iterate through each word in the SMS and increment the corresponding \n",
    "    # dictionary value by 1\n",
    "    for word in sms:\n",
    "        word_counts_per_sms[word][index] += 1\n",
    "\n",
    "# transform our word counter into a dataframe\n",
    "word_counts_per_sms = pd.DataFrame(word_counts_per_sms)\n",
    "\n",
    "# concatenate Dfs\n",
    "train_clean = pd.concat([train, word_counts_per_sms], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>0</th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>000pes</th>\n",
       "      <th>008704050406</th>\n",
       "      <th>0089</th>\n",
       "      <th>01223585334</th>\n",
       "      <th>...</th>\n",
       "      <th>zindgi</th>\n",
       "      <th>zoe</th>\n",
       "      <th>zogtorius</th>\n",
       "      <th>zouk</th>\n",
       "      <th>zyada</th>\n",
       "      <th>é</th>\n",
       "      <th>ú1</th>\n",
       "      <th>ü</th>\n",
       "      <th>〨ud</th>\n",
       "      <th>鈥</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1078</td>\n",
       "      <td>ham</td>\n",
       "      <td>[yep, by, the, pretty, sculpture]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4028</td>\n",
       "      <td>ham</td>\n",
       "      <td>[yes, princess, are, you, going, to, make, me,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>958</td>\n",
       "      <td>ham</td>\n",
       "      <td>[welp, apparently, he, retired]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4642</td>\n",
       "      <td>ham</td>\n",
       "      <td>[havent]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4674</td>\n",
       "      <td>ham</td>\n",
       "      <td>[i, forgot, 2, ask, ü, all, smth, there, s, a,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7786 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index Label                                                SMS  0  00  000  \\\n",
       "0   1078   ham                  [yep, by, the, pretty, sculpture]  0   0    0   \n",
       "1   4028   ham  [yes, princess, are, you, going, to, make, me,...  0   0    0   \n",
       "2    958   ham                    [welp, apparently, he, retired]  0   0    0   \n",
       "3   4642   ham                                           [havent]  0   0    0   \n",
       "4   4674   ham  [i, forgot, 2, ask, ü, all, smth, there, s, a,...  0   0    0   \n",
       "\n",
       "   000pes  008704050406  0089  01223585334 ...  zindgi  zoe  zogtorius  zouk  \\\n",
       "0       0             0     0            0 ...       0    0          0     0   \n",
       "1       0             0     0            0 ...       0    0          0     0   \n",
       "2       0             0     0            0 ...       0    0          0     0   \n",
       "3       0             0     0            0 ...       0    0          0     0   \n",
       "4       0             0     0            0 ...       0    0          0     0   \n",
       "\n",
       "   zyada  é  ú1  ü  〨ud  鈥  \n",
       "0      0  0   0  0    0  0  \n",
       "1      0  0   0  0    0  0  \n",
       "2      0  0   0  0    0  0  \n",
       "3      0  0   0  0    0  0  \n",
       "4      0  0   0  2    0  0  \n",
       "\n",
       "[5 rows x 7786 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check new output\n",
    "train_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing constants\n",
    "Now that the data is clean,we can begin to implement the algorithm. Before we begin, we need to compute some overall probabilities (constants) for our training set:\n",
    "- P(Spam): the probability that a message is spam\n",
    "- P(Ham): the probability that a message is ham\n",
    "- Nspam: the number of words in all the spam messages\n",
    "- Nham: the number of words in all the ham messages\n",
    "- Nvocabulary: the number of words in the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compute P(spam) by dividing the number of spam messages by the total\n",
    "p_spam = train_clean['Label'][train_clean['Label'] == 'spam'].count()/train_clean['Label'].count()\n",
    "\n",
    "# compute p_ham from p_spam\n",
    "p_ham = 1 - p_spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# compute N(spam)\n",
    "n_spam = train_clean[train_clean['Label']=='spam'].iloc[:,3:].sum(axis=1).sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# compute N(ham)\n",
    "n_ham = train_clean[train_clean['Label']=='ham'].iloc[:,3:].sum(axis=1).sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initiate variable alpha\n",
    "alpha = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compute N(vocabulary)\n",
    "n_vocabulary = len(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing parameters\n",
    "Naive Bayes classifiers are remarkably fast because much of the computational work is done before we even begin classification. Before we run the classifier, we need to compute various parameters relating the probabilities of encountering each word given that a message is spam or ham."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize two dictionaries, one for spam and one for ham, where each key-value\n",
    "# pair is a unique word from our vocabulary and the value is 0\n",
    "spam_dict = {unique_word: [0] for unique_word in vocabulary}\n",
    "ham_dict = {unique_word: [0] for unique_word in vocabulary}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# isolate spam and ham messages from training set into two different dataframes\n",
    "spam = train_clean[train_clean['Label'] == 'spam']\n",
    "ham = train_clean[train_clean['Label'] == 'ham']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# iterate over the vocabulary and compute the probability of each word given\n",
    "# spam and the probability of each word given ham. add the probabilities to their\n",
    "# respective dictionaries\n",
    "for word in vocabulary:\n",
    "    n_wi_spam = spam[word].sum()\n",
    "    p_wi_spam = (n_wi_spam + alpha)/(n_spam + alpha * n_vocabulary)\n",
    "    n_wi_ham = ham[word].sum()\n",
    "    p_wi_ham = (n_wi_ham + alpha)/(n_ham + alpha * n_vocabulary)\n",
    "    spam_dict[word] = p_wi_spam\n",
    "    ham_dict[word] = p_wi_ham"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the classification function\n",
    "Now that we have our parameters in place, we can build a function which parses messages from user input and classifies them. Remember that for each message we will need to perform a similar data cleaning operation that we did for our training set, standardizing the string input and splitting it into its component parts. From each word in the string, we can reference our vocabulary and parameters to compute the probability that the message is spam or ham, and output our classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import regex so we can parse the input string\n",
    "import re\n",
    "\n",
    "# function classify takes an SMS message as a string and outputs either \"Spam\",\n",
    "# \"Ham\", or a request for human help depending on the result of a Naive Bayes\n",
    "# classifier\n",
    "def classify(message):\n",
    "    \n",
    "    # Convert message into list of strings with all lowercase characters\n",
    "    message = re.sub('\\W', ' ', message).lower().split()\n",
    "    \n",
    "    # compute the probability that the message is spam and the probability of ham given the list of words\n",
    "    # the formula to compute this is to multiply the probability of spam by\n",
    "    # the sum of the probabilities of each word given spam.\n",
    "    \n",
    "    # initialize variables to report spam/ham probabilityies\n",
    "    p_spam_given_message = p_spam\n",
    "    p_ham_given_message = p_ham\n",
    "    \n",
    "    # iterate through each word in the message\n",
    "    for word in message:\n",
    "        # check if the word is in the spam dictionary\n",
    "        if word in spam_dict:\n",
    "            # if so, multiply our spam vairable by the value\n",
    "            p_spam_given_message *= spam_dict[word]\n",
    "            \n",
    "        # check if the word is in the ham dictionary\n",
    "        if word in ham_dict:\n",
    "            # if so, multiply our ham variable by the value\n",
    "            p_ham_given_message *= ham_dict[word]\n",
    "    \n",
    "    # compare the probabilities and report based on result\n",
    "    print('P(Spam|message):', p_spam_given_message)\n",
    "    print('P(Ham|message):', p_ham_given_message)\n",
    "        \n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        print('Label: Ham')\n",
    "    elif p_ham_given_message < p_spam_given_message:\n",
    "        print('Label: Spam')\n",
    "    else:\n",
    "        print('Equal proabilities, have a human classify this!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the classifier\n",
    "Let's start with two new messages of our own design:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message): 1.3481290211300841e-25\n",
      "P(Ham|message): 1.9368049028589875e-27\n",
      "Label: Spam\n"
     ]
    }
   ],
   "source": [
    "classify('WINNER!! This is the secret code to unlock the money: C3421.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message): 2.4372375665888117e-25\n",
      "P(Ham|message): 3.687530435009238e-21\n",
      "Label: Ham\n"
     ]
    }
   ],
   "source": [
    "classify('Sounds good, Tom, then see u there')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, testing a classifier against a sample of two is not very robust. Now, it's time to test our classification against the test set that we reserved earlier. We'll modify our classification function from above so that it returns the labels instead of printing them. This way we can feed the results into a new column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import regex so we can parse the input string\n",
    "import re\n",
    "\n",
    "# function classify takes an SMS message as a string and outputs either \"Spam\",\n",
    "# \"Ham\", or a request for human help depending on the result of a Naive Bayes\n",
    "# classifier\n",
    "def classify_test_set(message):\n",
    "    \n",
    "    # Convert message into list of strings with all lowercase characters\n",
    "    message = re.sub('\\W', ' ', message).lower().split()\n",
    "    \n",
    "    # compute the probability that the message is spam and the probability of ham given the list of words\n",
    "    # the formula to compute this is to multiply the probability of spam by\n",
    "    # the sum of the probabilities of each word given spam.\n",
    "    \n",
    "    # initialize variables to report spam/ham probabilityies\n",
    "    p_spam_given_message = p_spam\n",
    "    p_ham_given_message = p_ham\n",
    "    \n",
    "    # iterate through each word in the message\n",
    "    for word in message:\n",
    "        # check if the word is in the spam dictionary\n",
    "        if word in spam_dict:\n",
    "            # if so, multiply our spam vairable by the value\n",
    "            p_spam_given_message *= spam_dict[word]\n",
    "            \n",
    "        # check if the word is in the ham dictionary\n",
    "        if word in ham_dict:\n",
    "            # if so, multiply our ham variable by the value\n",
    "            p_ham_given_message *= ham_dict[word]\n",
    "        \n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        return 'ham'\n",
    "    elif p_ham_given_message < p_spam_given_message:\n",
    "        return 'spam'\n",
    "    else:\n",
    "        return 'needs human classification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2131</td>\n",
       "      <td>ham</td>\n",
       "      <td>Later i guess. I needa do mcat study too.</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3418</td>\n",
       "      <td>ham</td>\n",
       "      <td>But i haf enuff space got like 4 mb...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3424</td>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 10 mths? Update to latest Oran...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1538</td>\n",
       "      <td>ham</td>\n",
       "      <td>All sounds good. Fingers . Makes it difficult ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5393</td>\n",
       "      <td>ham</td>\n",
       "      <td>All done, all handed in. Don't know if mega sh...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index Label                                                SMS predicted\n",
       "0   2131   ham          Later i guess. I needa do mcat study too.       ham\n",
       "1   3418   ham             But i haf enuff space got like 4 mb...       ham\n",
       "2   3424  spam  Had your mobile 10 mths? Update to latest Oran...      spam\n",
       "3   1538   ham  All sounds good. Fingers . Makes it difficult ...       ham\n",
       "4   5393   ham  All done, all handed in. Don't know if mega sh...       ham"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate new column with predictions for test data\n",
    "test['predicted'] = test['SMS'].apply(classify_test_set)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can measure the accuracy by comparing the predictions to the true values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9874326750448833"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(test['predicted'] == test['Label']).sum() / test['Label'].count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
